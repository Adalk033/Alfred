"""
Demo r√°pida de la funcionalidad de GPU en Alfred
"""

print("="*60)
print("ALFRED - DEMO DE GPU")
print("="*60)
print()

print("1. Importando m√≥dulos...")
from gpu_manager import get_gpu_manager

print("2. Inicializando gestor de GPU...")
gpu = get_gpu_manager()

print("\n" + "="*60)
print("DETECCI√ìN DE HARDWARE")
print("="*60)

print(f"\n‚úì GPU detectada: {'S√ç' if gpu.has_gpu else 'NO'}")
print(f"‚úì Tipo de dispositivo: {gpu.device_type}")
print(f"‚úì PyTorch device: {gpu.device}")

if gpu.has_gpu:
    info = gpu.gpu_info
    print(f"\n‚ÑπÔ∏è Informaci√≥n detallada:")
    for key, value in info.items():
        if key != 'type':
            print(f"   ‚Ä¢ {key}: {value}")

print("\n" + "="*60)
print("CONFIGURACI√ìN DE OLLAMA")
print("="*60)

env_vars = gpu.configure_ollama_for_gpu()
print("\nVariables configuradas:")
for key, value in env_vars.items():
    print(f"   ‚Ä¢ {key} = {value}")

print("\n" + "="*60)
print("OPTIMIZACIONES")
print("="*60)

gpu.optimize_for_inference()
print("\n‚úì Optimizaciones aplicadas")

if gpu.has_gpu:
    print("\n" + "="*60)
    print("PRUEBA DE GPU")
    print("="*60)
    
    print("\nProbando operaci√≥n en GPU...")
    import torch
    
    try:
        device = gpu.get_torch_device()
        
        # Crear tensor en GPU
        tensor = torch.randn(100, 100).to(device)
        result = torch.matmul(tensor, tensor)
        
        print(f"‚úì Operaci√≥n exitosa en {device}")
        print(f"‚úì Shape del resultado: {result.shape}")
        
        # Ver memoria
        memory = gpu.get_memory_usage()
        if memory:
            print(f"\nüíæ Memoria GPU:")
            print(f"   ‚Ä¢ Asignada: {memory['allocated']:.4f} GB")
            print(f"   ‚Ä¢ Reservada: {memory['reserved']:.4f} GB")
        
        # Limpiar
        del tensor, result
        gpu.clear_cache()
        print("\n‚úì Memoria limpiada")
        
    except Exception as e:
        print(f"‚úó Error: {e}")

print("\n" + "="*60)
print("RECOMENDACIONES")
print("="*60)

if gpu.has_gpu:
    print("""
‚úì GPU detectada correctamente

Recomendaciones:
‚Ä¢ Usar modelos m√°s grandes (gemma2:9b, llama3:8b)
‚Ä¢ Aumentar k en retriever para m√°s contexto
‚Ä¢ Procesar documentos en lotes m√°s grandes

Para iniciar Alfred:
    python alfred.py
""")
else:
    print("""
‚ÑπÔ∏è No se detect√≥ GPU - Usando CPU

Recomendaciones:
‚Ä¢ Usar modelos m√°s peque√±os (gemma2:2b)
‚Ä¢ Reducir k en retriever
‚Ä¢ Considerar menos documentos simult√°neos

Para verificar GPU (NVIDIA):
    nvidia-smi

Para instalar PyTorch con CUDA:
    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

Para iniciar Alfred:
    python alfred.py
""")

print("="*60)
print("DEMO COMPLETADA")
print("="*60)

"""
Script de prueba r√°pida para ver cambios en GPU
Hace una consulta simple a Ollama para que veas el aumento de uso de GPU
"""

import requests
import json
import time

def test_ollama_gpu():
    """Hacer una consulta a Ollama y mostrar estad√≠sticas"""
    
    print("=" * 70)
    print("PRUEBA DE GPU CON OLLAMA")
    print("=" * 70)
    print("\nüîç Abre otra terminal y ejecuta uno de estos:")
    print("   ‚Ä¢ python monitor_gpu_usage.py")
    print("   ‚Ä¢ nvidia-smi -l 1")
    print("   ‚Ä¢ .\\watch_gpu.ps1")
    print("\nLuego vuelve aqu√≠ y presiona ENTER para hacer una consulta...")
    input()
    
    print("\nüì§ Enviando consulta a Ollama...")
    print("‚è±Ô∏è  Observa el monitor GPU en la otra terminal - ver√°s:")
    print("   ‚Ä¢ GPU Usage subir de ~5% a 80-100%")
    print("   ‚Ä¢ Memory Usage aumentar")
    print("   ‚Ä¢ Temperatura subir ligeramente\n")
    
    url = "http://localhost:11434/api/generate"
    
    payload = {
        "model": "qwen2.5:7b",
        "prompt": "Explica en 3 l√≠neas qu√© es la inteligencia artificial.",
        "stream": True
    }
    
    try:
        start_time = time.time()
        response = requests.post(url, json=payload, stream=True, timeout=60)
        
        print("üí¨ Respuesta de Ollama:")
        print("-" * 70)
        
        full_response = ""
        for line in response.iter_lines():
            if line:
                try:
                    data = json.loads(line)
                    if 'response' in data:
                        chunk = data['response']
                        print(chunk, end='', flush=True)
                        full_response += chunk
                    
                    if data.get('done', False):
                        break
                except json.JSONDecodeError:
                    continue
        
        elapsed = time.time() - start_time
        
        print("\n" + "-" * 70)
        print(f"‚úì Consulta completada en {elapsed:.2f} segundos")
        print("\nüîç Revisa la otra terminal - deber√≠as haber visto:")
        print("   ‚Ä¢ GPU Usage en 80-100% durante el procesamiento")
        print("   ‚Ä¢ Memory Usage aument√≥ temporalmente")
        print("   ‚Ä¢ Ahora vuelve a niveles normales (~5%)")
        
    except requests.exceptions.ConnectionError:
        print("‚ùå Error: No se pudo conectar a Ollama")
        print("   Aseg√∫rate de que Ollama est√© corriendo:")
        print("   ‚Ä¢ ollama serve")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
    
    print("\n" + "=" * 70)
    print("PRUEBA COMPLETADA")
    print("=" * 70)
    print("\nüí° Para m√°s pruebas, simplemente ejecuta este script de nuevo")


if __name__ == "__main__":
    test_ollama_gpu()
